# VMI æµ‹è¯•æ¡†æ¶

## ğŸ“‹ æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„VMIï¼ˆä¾›åº”å•†ç®¡ç†åº“å­˜ï¼‰ç³»ç»Ÿæµ‹è¯•æ¡†æ¶ï¼Œæä¾›ç»Ÿä¸€çš„æµ‹è¯•ç®¡ç†ã€å¹¶å‘å‹åŠ›æµ‹è¯•ã€æ€§èƒ½ç›‘æ§å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# æ¿€æ´»Pythonè™šæ‹Ÿç¯å¢ƒ
source /home/rangh/codespace/venv/bin/activate

# å®‰è£…ä¾èµ–åŒ…ï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰
pip install pytest coverage matplotlib numpy
```

### 2. éªŒè¯æµ‹è¯•æ¡†æ¶

```bash
# è¿è¡Œæ¡†æ¶éªŒè¯è„šæœ¬
python test_framework_validation.py
```

### 3. è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•ï¼ˆåŸºç¡€+å¹¶å‘+åœºæ™¯ï¼‰
python test_runner.py --mode all --env test

# æˆ–ä½¿ç”¨pytestç›´æ¥è¿è¡Œ
python -m pytest concurrent_test.py -v
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
vmi/
â”œâ”€â”€ README.md                      # æœ¬æ–‡æ¡£
â”œâ”€â”€ test_config.py                 # é…ç½®ç®¡ç†ç³»ç»Ÿ
â”œâ”€â”€ test_base.py                   # æµ‹è¯•åŸºç±»å’Œå·¥å…·å‡½æ•°
â”œâ”€â”€ concurrent_test.py             # å¹¶å‘å‹åŠ›æµ‹è¯•æ¨¡å—
â”œâ”€â”€ scenario_test.py               # ä¸šåŠ¡åœºæ™¯æµ‹è¯•
â”œâ”€â”€ test_runner.py                 # æµ‹è¯•æ‰§è¡Œè„šæœ¬ï¼ˆä¸»å…¥å£ï¼‰
â”œâ”€â”€ test_adapter.py                # æµ‹è¯•é€‚é…å™¨ï¼ˆè¿ç§»ç°æœ‰æµ‹è¯•ï¼‰
â”œâ”€â”€ performance_report.py          # æ€§èƒ½ç›‘æ§å’ŒæŠ¥å‘Šç³»ç»Ÿ
â”œâ”€â”€ test_framework_validation.py   # æ¡†æ¶éªŒè¯è„šæœ¬
â”œâ”€â”€ TEST_FRAMEWORK_README.md       # è¯¦ç»†æŠ€æœ¯æ–‡æ¡£
â”œâ”€â”€ setup_env.py                   # ç¯å¢ƒè®¾ç½®è„šæœ¬ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ run_tests.py                   # æµ‹è¯•è¿è¡ŒåŒ…è£…å™¨ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ session_mock.py                # å¤‡ä»½çš„æ¨¡æ‹Ÿsessionæ¨¡å—
â”œâ”€â”€ cas_mock/                      # å¤‡ä»½çš„æ¨¡æ‹Ÿcasæ¨¡å—
â”œâ”€â”€ warehouse/                     # ä»“åº“ç›¸å…³æµ‹è¯•
â”œâ”€â”€ store/                         # åº—é“ºç›¸å…³æµ‹è¯•
â”œâ”€â”€ product/                       # äº§å“ç›¸å…³æµ‹è¯•
â”œâ”€â”€ partner/                       # åˆä½œä¼™ä¼´æµ‹è¯•
â””â”€â”€ credit/                        # ä¿¡ç”¨ç›¸å…³æµ‹è¯•
```

## ğŸ› ï¸ æ ¸å¿ƒåŠŸèƒ½

### 1. çœŸå®æœåŠ¡å™¨äº¤äº’ç³»ç»Ÿ

**é‡è¦æ›´æ–°**ï¼šæµ‹è¯•æ¡†æ¶ç°åœ¨ä¸çœŸå®çš„VMIæœåŠ¡å™¨è¿›è¡Œäº¤äº’ï¼Œä¸å†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å—ã€‚

**çœŸå®æ¨¡å—è·¯å¾„**ï¼š
- Sessionæ¨¡å—ï¼š`/home/rangh/codespace/magicTest/session/`
- CASæ¨¡å—ï¼š`/home/rangh/codespace/magicTest/cas/cas/cas.py`

**æœåŠ¡å™¨é…ç½®**ï¼š
- æœåŠ¡å™¨URLï¼š`https://autotest.local.vpc`
- é»˜è®¤å‡­è¯ï¼š`administrator` / `administrator`
- å‘½åç©ºé—´ï¼š`default`

**ç¯å¢ƒè®¾ç½®**ï¼š
```bash
# ä½¿ç”¨ç¯å¢ƒè®¾ç½®è„šæœ¬
python setup_env.py

# æˆ–ä½¿ç”¨æµ‹è¯•åŒ…è£…å™¨
python run_tests.py --test-file store/store_test.py
```

### 2. é…ç½®ç®¡ç†ç³»ç»Ÿ (`test_config.py`)

æ”¯æŒ4ç§æµ‹è¯•æ¨¡å¼å’Œ4ç§ç¯å¢ƒé…ç½®ï¼š

**æµ‹è¯•æ¨¡å¼**ï¼š
- `development` - å¼€å‘ç¯å¢ƒï¼ˆé»˜è®¤ï¼‰
- `test` - æµ‹è¯•ç¯å¢ƒ
- `pressure` - å‹åŠ›æµ‹è¯•ç¯å¢ƒ
- `production` - ç”Ÿäº§ç¯å¢ƒï¼ˆåªè¯»ï¼‰

**ç¯å¢ƒé…ç½®**ï¼š
- `dev` - å¼€å‘ç¯å¢ƒ
- `test` - æµ‹è¯•ç¯å¢ƒ
- `stress` - å‹åŠ›æµ‹è¯•ç¯å¢ƒ
- `prod` - ç”Ÿäº§ç¯å¢ƒ

### 2. ç»Ÿä¸€æµ‹è¯•åŸºç±» (`test_base.py`)

æ‰€æœ‰æµ‹è¯•ç»§æ‰¿ `TestBase` ç±»ï¼Œæä¾›ï¼š
- ç»Ÿä¸€çš„ä¼šè¯ç®¡ç†
- è‡ªåŠ¨é…ç½®åŠ è½½
- æ€§èƒ½ç›‘æ§é›†æˆ
- æ•°æ®æ¸…ç†å·¥å…·

### 3. å¹¶å‘å‹åŠ›æµ‹è¯• (`concurrent_test.py`)

åŒ…å«5ä¸ªå¹¶å‘æµ‹è¯•åœºæ™¯ï¼š
1. `test_concurrent_store_creation` - å¹¶å‘åˆ›å»ºåº—é“ºï¼ˆ50ä¸ªè¯·æ±‚ï¼‰
2. `test_concurrent_goods_operations` - å¹¶å‘å•†å“æ“ä½œï¼ˆ30ä¸ªè¯·æ±‚ï¼‰
3. `test_mixed_concurrent_operations` - æ··åˆå¹¶å‘æ“ä½œï¼ˆ100ä¸ªè¯·æ±‚ï¼‰
4. `test_concurrent_shelf_management` - å¹¶å‘è´§æ¶ç®¡ç†ï¼ˆ20ä¸ªè¯·æ±‚ï¼‰
5. `test_concurrent_stock_operations` - å¹¶å‘åº“å­˜æ“ä½œï¼ˆ60ä¸ªè¯·æ±‚ï¼‰

### 4. æ€§èƒ½ç›‘æ§ (`performance_report.py`)

è‡ªåŠ¨æ”¶é›†æ€§èƒ½æŒ‡æ ‡ï¼š
- å“åº”æ—¶é—´ï¼ˆå¹³å‡ã€æœ€å°ã€æœ€å¤§ï¼‰
- ååé‡ï¼ˆè¯·æ±‚/ç§’ï¼‰
- æˆåŠŸç‡
- é”™è¯¯è¯¦æƒ…

## ğŸ“Š ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1ï¼šä½¿ç”¨æµ‹è¯•è¿è¡Œå™¨ï¼ˆæ¨èï¼‰

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python test_runner.py --mode all --env test

# åªè¿è¡Œå¹¶å‘æµ‹è¯•
python test_runner.py --mode concurrent --env stress

# åªè¿è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_runner.py --mode basic --env test

# åªè¿è¡Œåœºæ™¯æµ‹è¯•
python test_runner.py --mode scenario --env test

# æŸ¥çœ‹å¸®åŠ©
python test_runner.py --help
```

### æ–¹æ³•2ï¼šä½¿ç”¨pytest

```bash
# è¿è¡Œæ‰€æœ‰å¹¶å‘æµ‹è¯•
python -m pytest concurrent_test.py -v

# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»
python -m pytest concurrent_test.py::ConcurrentStoreTest -v

# è¿è¡Œå•ä¸ªæµ‹è¯•æ–¹æ³•
python -m pytest concurrent_test.py::ConcurrentStoreTest::test_concurrent_store_creation -v

# è¿è¡Œç°æœ‰æµ‹è¯•
python -m pytest store/store_test.py::StoreTestCase::test_create_store -v
```

### æ–¹æ³•3ï¼šç›´æ¥è¿è¡Œæµ‹è¯•æ–‡ä»¶

```bash
# è¿è¡Œå¹¶å‘æµ‹è¯•
python concurrent_test.py

# è¿è¡Œæ¡†æ¶éªŒè¯
python test_framework_validation.py

# è¿è¡Œæµ‹è¯•é€‚é…å™¨
python test_adapter.py --migrate
```

## ğŸ”§ é…ç½®è¯´æ˜

### é…ç½®æ–‡ä»¶

æµ‹è¯•é…ç½®é€šè¿‡ `test_config.py` ç®¡ç†ï¼Œæ”¯æŒä»¥ä¸‹å‚æ•°ï¼š

```python
# æœåŠ¡å™¨é…ç½®
server_url = "https://autotest.local.vpc"
namespace = "default"

# å¹¶å‘æµ‹è¯•å‚æ•°
concurrent_params = {
    "max_workers": 10,
    "timeout": 30,
    "retry_count": 3
}

# æ€§èƒ½é˜ˆå€¼
performance_thresholds = {
    "avg_response_time": 2.0,  # ç§’
    "success_rate": 95.0,      # ç™¾åˆ†æ¯”
    "throughput": 10.0         # è¯·æ±‚/ç§’
}
```

### ç¯å¢ƒå˜é‡

å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®ï¼š

```bash
# è®¾ç½®æµ‹è¯•æ¨¡å¼
export TEST_MODE=pressure

# è®¾ç½®æœåŠ¡å™¨URL
export TEST_SERVER_URL=https://test.example.com

# è®¾ç½®å‘½åç©ºé—´
export TEST_NAMESPACE=vmi_test
```

## ğŸ“ˆ æµ‹è¯•æŠ¥å‘Š

### è‡ªåŠ¨ç”Ÿæˆçš„æŠ¥å‘Š

æ¯æ¬¡æµ‹è¯•è¿è¡Œä¼šè‡ªåŠ¨ç”ŸæˆJSONæ ¼å¼çš„æŠ¥å‘Šæ–‡ä»¶ï¼š
```
test_report_YYYYMMDD_HHMMSS.json
```

æŠ¥å‘Šå†…å®¹åŒ…å«ï¼š
- æµ‹è¯•æ‰§è¡Œæ—¶é—´
- å„æµ‹è¯•ç±»å‹ç»“æœ
- æ€§èƒ½æŒ‡æ ‡
- ç¯å¢ƒé…ç½®
- æ€»ä½“ç»Ÿè®¡

### æŸ¥çœ‹æŠ¥å‘Š

```bash
# æŸ¥çœ‹æœ€æ–°æŠ¥å‘Š
ls -la test_report_*.json

# æŸ¥çœ‹æŠ¥å‘Šå†…å®¹
cat test_report_20260128_183051.json | python -m json.tool
```

### æ€§èƒ½æŠ¥å‘Šç¤ºä¾‹

```json
{
  "timestamp": "2026-01-28T18:30:51.942887",
  "total_duration": 0.313372,
  "test_results": [
    {
      "test_type": "concurrent",
      "total_tests": 5,
      "failures": 0,
      "errors": 0,
      "successful": 5,
      "success_rate": 100.0
    }
  ],
  "summary": {
    "total_tests": 5,
    "total_successful": 5,
    "total_failures": 0,
    "total_errors": 0,
    "overall_success_rate": 100.0,
    "status": "PASS"
  }
}
```

## ğŸ§ª æµ‹è¯•ç±»å‹è¯´æ˜

### 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•

æµ‹è¯•VMIç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ï¼š
- åº—é“ºç®¡ç†ï¼ˆåˆ›å»ºã€æŸ¥è¯¢ã€æ›´æ–°ã€åˆ é™¤ï¼‰
- å•†å“ç®¡ç†
- åº“å­˜ç®¡ç†ï¼ˆå…¥åº“ã€å‡ºåº“ï¼‰
- ä»“åº“ç®¡ç†
- è´§æ¶ç®¡ç†

### 2. å¹¶å‘å‹åŠ›æµ‹è¯•

æ¨¡æ‹Ÿå¤šç”¨æˆ·å¹¶å‘åœºæ™¯ï¼š
- å¹¶å‘åˆ›å»ºå®ä½“
- å¹¶å‘æ›´æ–°æ“ä½œ
- æ··åˆè¯»å†™æ“ä½œ
- æ•°æ®ä¸€è‡´æ€§éªŒè¯

### 3. ä¸šåŠ¡åœºæ™¯æµ‹è¯•

åŸºäºçœŸå®ä¸šåŠ¡åœºæ™¯ï¼š
- å•ç§Ÿæˆ·å®Œæ•´ä¸šåŠ¡æµç¨‹
- ç«¯åˆ°ç«¯æµ‹è¯•
- ä¸šåŠ¡è§„åˆ™éªŒè¯

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **çœŸå®æœåŠ¡å™¨è¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥æœåŠ¡å™¨å¯è®¿é—®æ€§
   curl -k https://autotest.local.vpc
   
   # æ£€æŸ¥Pythonè·¯å¾„è®¾ç½®
   python setup_env.py --verify
   
   # éªŒè¯çœŸå®æ¨¡å—å¯¼å…¥
   python -c "
   import sys
   sys.path.insert(0, '/home/rangh/codespace/magicTest')
   sys.path.insert(0, '/home/rangh/codespace/magicTest/cas')
   try:
       from cas.cas import Cas
       print('âœ… CASæ¨¡å—å¯¼å…¥æˆåŠŸ')
   except Exception as e:
       print('âŒ CASæ¨¡å—å¯¼å…¥å¤±è´¥:', e)
   "
   ```

2. **SSLè¯ä¹¦è­¦å‘Š**
   ```bash
   # æµ‹è¯•ç¯å¢ƒä½¿ç”¨è‡ªç­¾åè¯ä¹¦ï¼Œè­¦å‘Šæ­£å¸¸
   # å¦‚éœ€ç¦ç”¨SSLéªŒè¯ï¼ˆä»…æµ‹è¯•ç¯å¢ƒï¼‰
   export TEST_DISABLE_SSL_VERIFY=true
   ```

3. **å¹¶å‘æµ‹è¯•å¤±è´¥ï¼šæœåŠ¡å™¨è´Ÿè½½è¿‡é«˜**
   ```bash
   # å‡å°‘å¹¶å‘æ•°
   export TEST_MAX_WORKERS=5
   export TEST_CONCURRENT_REQUESTS=10
   
   # å¢åŠ è¶…æ—¶æ—¶é—´
   export TEST_TIMEOUT=60
   ```

4. **æµ‹è¯•æ•°æ®æ¸…ç†é—®é¢˜**
   ```bash
   # æµ‹è¯•ä¼šåœ¨æœåŠ¡å™¨ä¸Šåˆ›å»ºçœŸå®æ•°æ®
   # ç¡®ä¿æœ‰é€‚å½“çš„æ•°æ®æ¸…ç†æœºåˆ¶
   # æˆ–ä½¿ç”¨æµ‹è¯•ä¸“ç”¨å‘½åç©ºé—´
   export TEST_NAMESPACE=vmi_test
   ```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export TEST_DEBUG=true

# å¯ç”¨æ€§èƒ½è¯¦ç»†æ—¥å¿—
export PERFORMANCE_DEBUG=true

# è¿è¡Œæµ‹è¯•
python test_runner.py --mode all --env test
```

## ğŸ“ ç¼–å†™æ–°æµ‹è¯•

### ç»§æ‰¿TestBase

```python
from test_base import TestBase

class MyNewTest(TestBase):
    def setUp(self):
        super().setUp()
        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®
    
    def test_my_feature(self):
        # ç¼–å†™æµ‹è¯•é€»è¾‘
        result = self.perform_operation()
        self.assertTrue(result)
    
    def tearDown(self):
        # æ¸…ç†æµ‹è¯•æ•°æ®
        super().tearDown()
```

### ä½¿ç”¨å¹¶å‘æµ‹è¯•æ¡†æ¶

```python
from test_base import TestBase, ConcurrentTestMixin
from concurrent_test import ConcurrentTestRunner, ConcurrentTestFactory

class MyConcurrentTest(TestBase, ConcurrentTestMixin):
    def test_concurrent_operation(self):
        runner = ConcurrentTestRunner(max_workers=10)
        
        def operation(worker_id: int):
            return {"data": f"test_{worker_id}"}
        
        test_func = ConcurrentTestFactory.create_create_test(
            self.__class__, 'entity_type', operation
        )
        
        result = runner.run_concurrent_test(
            test_func,
            'my_concurrent_test',
            num_requests=50
        )
        
        self.assertGreaterEqual(result.successful_requests, 45)
```

### ä½¿ç”¨æ€§èƒ½ç›‘æ§

```python
from performance_report import PerformanceMonitor

class MyPerformanceTest(TestBase):
    def test_performance(self):
        monitor = PerformanceMonitor()
        
        with monitor.measure('my_operation'):
            # æ‰§è¡Œéœ€è¦ç›‘æ§çš„æ“ä½œ
            result = self.expensive_operation()
        
        metrics = monitor.get_metrics()
        self.assertLess(metrics['my_operation']['avg_time'], 1.0)
```

## ğŸ”„ è¿ç§»ç°æœ‰æµ‹è¯•

### è‡ªåŠ¨è¿ç§»

```bash
# è¿è¡Œæµ‹è¯•é€‚é…å™¨
python test_adapter.py --migrate
```

### æ‰‹åŠ¨é€‚é…

ç°æœ‰æµ‹è¯•æ— éœ€ä¿®æ”¹å³å¯è¿è¡Œï¼Œä½†å¦‚æœéœ€è¦é›†æˆæ–°åŠŸèƒ½ï¼š

```python
# åœ¨ç°æœ‰æµ‹è¯•ä¸­æ·»åŠ 
from test_adapter import LegacyTestAdapter

class MyExistingTest(LegacyTestAdapter):
    # ç°åœ¨å¯ä»¥ä½¿ç”¨æ‰€æœ‰æ–°æ¡†æ¶åŠŸèƒ½
    def test_with_new_features(self):
        # ä½¿ç”¨æ€§èƒ½ç›‘æ§
        self.performance_monitor.record_metric('my_metric', 0.5)
        
        # ä½¿ç”¨é…ç½®ç®¡ç†
        mode = self._config.get_test_mode()
        print(f"å½“å‰æµ‹è¯•æ¨¡å¼: {mode}")
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. çœŸå®æœåŠ¡å™¨æµ‹è¯•
- **ç¯å¢ƒéš”ç¦»**ï¼šåœ¨ä¸“ç”¨æµ‹è¯•ç¯å¢ƒè¿è¡Œ
- **æ•°æ®ç®¡ç†**ï¼šæµ‹è¯•åæ¸…ç†åˆ›å»ºçš„æ•°æ®
- **å‡­è¯å®‰å…¨**ï¼šä½¿ç”¨æµ‹è¯•ä¸“ç”¨è´¦æˆ·
- **ç›‘æ§å‘Šè­¦**ï¼šç›‘æ§æœåŠ¡å™¨æ€§èƒ½å’Œèµ„æºä½¿ç”¨

### 2. å¹¶å‘æµ‹è¯•ä¼˜åŒ–
- **æ¸è¿›å¼è´Ÿè½½**ï¼šä»ä½å¹¶å‘å¼€å§‹ï¼Œé€æ­¥å¢åŠ 
- **æ€§èƒ½åŸºå‡†**ï¼šå»ºç«‹æ€§èƒ½åŸºå‡†çº¿
- **é”™è¯¯é‡è¯•**ï¼šå®ç°æ™ºèƒ½é‡è¯•æœºåˆ¶
- **èµ„æºç›‘æ§**ï¼šç›‘æ§æœåŠ¡å™¨CPUã€å†…å­˜ã€ç½‘ç»œ

### 3. æµ‹è¯•æ•°æ®ç­–ç•¥
- **æµ‹è¯•ä¸“ç”¨æ•°æ®**ï¼šä½¿ç”¨ä¸“ç”¨æµ‹è¯•æ•°æ®
- **æ•°æ®éš”ç¦»**ï¼šä½¿ç”¨æµ‹è¯•å‘½åç©ºé—´
- **è‡ªåŠ¨æ¸…ç†**ï¼šå®ç°æµ‹è¯•æ•°æ®è‡ªåŠ¨æ¸…ç†
- **æ•°æ®éªŒè¯**ï¼šéªŒè¯æœåŠ¡å™¨æ•°æ®ä¸€è‡´æ€§

### 4. é”™è¯¯å¤„ç†ä¸è°ƒè¯•
- **è¯¦ç»†æ—¥å¿—**ï¼šè®°å½•å®Œæ•´çš„è¯·æ±‚/å“åº”ä¿¡æ¯
- **é”™è¯¯åˆ†ç±»**ï¼šåŒºåˆ†ç½‘ç»œé”™è¯¯ã€æœåŠ¡å™¨é”™è¯¯ã€ä¸šåŠ¡é”™è¯¯
- **é‡è¯•ç­–ç•¥**ï¼šå¯¹ä¸´æ—¶æ€§é”™è¯¯å®ç°è‡ªåŠ¨é‡è¯•
- **è°ƒè¯•å·¥å…·**ï¼šæä¾›ä¸“é—¨çš„è°ƒè¯•è„šæœ¬å’Œå·¥å…·

## ğŸ“ æ”¯æŒä¸åé¦ˆ

### è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹æ¡†æ¶æ–‡æ¡£
cat TEST_FRAMEWORK_README.md

# è¿è¡Œå¸®åŠ©å‘½ä»¤
python test_runner.py --help
python test_adapter.py --help
```

### æŠ¥å‘Šé—®é¢˜

é‡åˆ°é—®é¢˜æ—¶ï¼Œè¯·æä¾›ï¼š
1. å®Œæ•´çš„é”™è¯¯ä¿¡æ¯
2. æµ‹è¯•å‘½ä»¤å’Œå‚æ•°
3. ç¯å¢ƒä¿¡æ¯ï¼ˆPythonç‰ˆæœ¬ã€æ“ä½œç³»ç»Ÿï¼‰
4. ç›¸å…³é…ç½®æ–‡ä»¶

### è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. ç¼–å†™æµ‹è¯•ç”¨ä¾‹
4. è¿è¡Œç°æœ‰æµ‹è¯•ç¡®ä¿é€šè¿‡
5. æäº¤Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚è¯¦è§LICENSEæ–‡ä»¶ã€‚

## ğŸ† è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…å’Œæµ‹è¯•äººå‘˜ï¼Œç‰¹åˆ«æ„Ÿè°¢ï¼š
- æµ‹è¯•æ¡†æ¶è®¾è®¡å›¢é˜Ÿ
- æ€§èƒ½ä¼˜åŒ–è´¡çŒ®è€…
- æ–‡æ¡£ç¼–å†™äººå‘˜

---

**æœ€åæ›´æ–°**: 2026-01-28  
**ç‰ˆæœ¬**: 2.0.0  
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ªï¼ˆçœŸå®æœåŠ¡å™¨äº¤äº’ï¼‰