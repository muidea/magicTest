#!/usr/bin/env python3
"""
VMI ç»Ÿä¸€æµ‹è¯•å…¥å£
æ•´åˆæ‰€æœ‰æµ‹è¯•è¿è¡Œæ¨¡å¼ï¼Œæ”¯æŒ unittest å’Œ pytest

ä½¿ç”¨æ–¹æ³•ï¼š
    python3 run_tests.py --all           # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    python3 run_tests.py --quick         # å¿«é€ŸéªŒè¯
    python3 run_tests.py --concurrent    # å¹¶å‘æµ‹è¯•
    python3 run_tests.py --scenario      # åœºæ™¯æµ‹è¯•
    python3 run_tests.py --aging 60      # è€åŒ–æµ‹è¯•ï¼ˆ60åˆ†é’Ÿï¼‰
    python3 run_tests.py --multi-tenant  # å¤šç§Ÿæˆ·æµ‹è¯•
    python3 run_tests.py --validation    # æ¡†æ¶éªŒè¯æµ‹è¯•
    python3 run_tests.py --module        # æ¨¡å—æµ‹è¯•
    python3 run_tests.py --pytest --all  # ä½¿ç”¨ pytest è¿è¡Œ
"""

import argparse
import json
import os
import subprocess
import sys
import time
from datetime import datetime
from typing import Any, Dict, List, Tuple

CONFIG_FILE = os.path.join(os.path.dirname(__file__), "test_config.json")


def load_config() -> Dict[str, Any]:
    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
        return {}


def run_command(cmd: str, description: str = "") -> Tuple[bool, float]:
    print(f"\n{'='*60}")
    print(f"æ‰§è¡Œ: {description}")
    print(f"å‘½ä»¤: {cmd}")
    print(f"{'='*60}")

    start_time = time.time()
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        elapsed = time.time() - start_time

        if result.stdout:
            print(result.stdout)

        if result.stderr and result.returncode != 0:
            print(f"é”™è¯¯: {result.stderr}")

        print(f"\næ‰§è¡Œæ—¶é—´: {elapsed:.2f}ç§’")

        return result.returncode == 0, elapsed
    except Exception as e:
        print(f"æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
        return False, 0


def run_pytest_command(
    pytest_args: List[str], description: str = ""
) -> Tuple[bool, float]:
    cmd = "pytest " + " ".join(pytest_args)
    return run_command(cmd, description)


def run_validation_tests(pytest_mode: bool = False) -> Tuple[bool, float]:
    """è¿è¡Œæ¡†æ¶éªŒè¯æµ‹è¯•ï¼ˆåŒ…å«åŸºç¡€åŠŸèƒ½å’Œä¼šè¯ç®¡ç†éªŒè¯ï¼‰"""
    print("\nâœ… è¿è¡Œæ¡†æ¶éªŒè¯æµ‹è¯•")

    if pytest_mode:
        return run_pytest_command(
            ["test_complete_validation.py", "-v", "--tb=short"], "æ¡†æ¶éªŒè¯æµ‹è¯• (pytest)"
        )

    cmd = "python3 test_complete_validation.py"
    return run_command(cmd, "æ¡†æ¶éªŒè¯æµ‹è¯•")


def run_multi_tenant_tests(pytest_mode: bool = False) -> Tuple[bool, float]:
    """è¿è¡Œå¤šç§Ÿæˆ·æµ‹è¯•"""
    print("\nğŸ¢ è¿è¡Œå¤šç§Ÿæˆ·æµ‹è¯•")

    if pytest_mode:
        return run_pytest_command(
            [
                "test_multi_tenant.py",
                "test_multi_tenant_example.py",
                "-v",
                "--tb=short",
            ],
            "å¤šç§Ÿæˆ·æµ‹è¯• (pytest)",
        )

    cmd = "python3 test_multi_tenant.py"
    return run_command(cmd, "å¤šç§Ÿæˆ·æµ‹è¯•")


def run_concurrent_tests(pytest_mode: bool = False) -> Tuple[bool, float]:
    """è¿è¡Œå¹¶å‘æµ‹è¯•"""
    print("\nâš¡ è¿è¡Œå¹¶å‘æµ‹è¯•")

    if pytest_mode:
        return run_pytest_command(
            ["concurrent_test_v2.py", "-v", "--tb=short"], "å¹¶å‘æµ‹è¯• (pytest)"
        )

    cmd = "python3 concurrent_test_v2.py"
    return run_command(cmd, "å¹¶å‘æµ‹è¯•")


def run_scenario_tests(pytest_mode: bool = False) -> Tuple[bool, float]:
    """è¿è¡Œåœºæ™¯æµ‹è¯•"""
    print("\nğŸ­ è¿è¡Œåœºæ™¯æµ‹è¯•")

    if pytest_mode:
        return run_pytest_command(
            ["scenario_test.py", "-v", "--tb=short"], "åœºæ™¯æµ‹è¯• (pytest)"
        )

    cmd = "python3 scenario_test.py"
    return run_command(cmd, "åœºæ™¯æµ‹è¯•")


def run_aging_tests(
    duration: int = 60, pytest_mode: bool = False
) -> Tuple[bool, float]:
    """è¿è¡Œè€åŒ–æµ‹è¯•"""
    print(f"\nâ³ è¿è¡Œè€åŒ–æµ‹è¯•ï¼ˆ{duration}åˆ†é’Ÿï¼‰")

    if pytest_mode:
        os.environ["AGING_TEST_DURATION"] = str(duration / 60.0)
        os.environ["AGING_TEST_THREADS"] = "2"
        success, elapsed = run_pytest_command(
            ["aging_test_simple.py", "-v", "--tb=short"],
            f"è€åŒ–æµ‹è¯• ({duration}åˆ†é’Ÿ) - pytest",
        )
        os.environ.pop("AGING_TEST_DURATION", None)
        os.environ.pop("AGING_TEST_THREADS", None)
        return success, elapsed

    cmd = f"python3 aging_test_simple.py --duration {duration}"
    return run_command(cmd, f"è€åŒ–æµ‹è¯• ({duration}åˆ†é’Ÿ)")


def run_module_tests(pytest_mode: bool = False) -> Tuple[bool, float]:
    """è¿è¡Œæ¨¡å—æµ‹è¯•"""
    print("\nğŸ“¦ è¿è¡Œæ¨¡å—æµ‹è¯•")

    if pytest_mode:
        return run_pytest_command(
            [
                "./store",
                "./credit",
                "./order",
                "./product",
                "./warehouse",
                "./partner",
                "./status",
                "-v",
                "--tb=short",
            ],
            "æ¨¡å—æµ‹è¯• (pytest)",
        )

    cmd = "python3 -m unittest discover -s . -p '*_test.py' -v"
    return run_command(cmd, "æ¨¡å—æµ‹è¯•")


def run_all_tests(pytest_mode: bool = False) -> List[Tuple[str, bool, float]]:
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸ” è¿è¡Œæ‰€æœ‰æµ‹è¯•")

    results = []

    results.append(("æ¡†æ¶éªŒè¯æµ‹è¯•", *run_validation_tests(pytest_mode)))
    results.append(("å¤šç§Ÿæˆ·æµ‹è¯•", *run_multi_tenant_tests(pytest_mode)))
    results.append(("å¹¶å‘æµ‹è¯•", *run_concurrent_tests(pytest_mode)))
    results.append(("åœºæ™¯æµ‹è¯•", *run_scenario_tests(pytest_mode)))
    results.append(("æ¨¡å—æµ‹è¯•", *run_module_tests(pytest_mode)))

    return results


def run_quick_tests(pytest_mode: bool = False) -> List[Tuple[str, bool, float]]:
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆä»…æ¡†æ¶éªŒè¯ï¼‰"""
    print("\nâš¡ è¿è¡Œå¿«é€Ÿæµ‹è¯•")

    results = []
    results.append(("æ¡†æ¶éªŒè¯æµ‹è¯•", *run_validation_tests(pytest_mode)))

    return results


def generate_report(results: List[Tuple[str, bool, float]]) -> None:
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æ‰§è¡ŒæŠ¥å‘Š")
    print("=" * 60)

    total_tests = len(results)
    passed_tests = sum(1 for _, success, _ in results if success)
    failed_tests = total_tests - passed_tests
    total_time = sum(elapsed for _, _, elapsed in results)

    print(f"æ€»æµ‹è¯•å¥—ä»¶: {total_tests}")
    print(f"é€šè¿‡: {passed_tests}")
    print(f"å¤±è´¥: {failed_tests}")
    print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")

    if total_tests > 0:
        print(f"é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}%")

    print("\nè¯¦ç»†ç»“æœ:")
    for test_name, success, elapsed in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status} ({elapsed:.2f}ç§’)")

    if failed_tests > 0:
        print(f"\nâš ï¸ å¤±è´¥çš„æµ‹è¯•:")
        for test_name, success, _ in results:
            if not success:
                print(f"  - {test_name}")

    print(f"\næŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def check_config_status() -> None:
    """æ£€æŸ¥é…ç½®çŠ¶æ€"""
    print("\nğŸ” æ£€æŸ¥é…ç½®çŠ¶æ€")

    print(f"é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
    if os.path.exists(CONFIG_FILE):
        config = load_config()
        print(f"æœåŠ¡å™¨: {config.get('server', {}).get('url', 'N/A')}")
        print(f"å‘½åç©ºé—´: {config.get('server', {}).get('namespace', 'N/A')}")
        print(f"ç¯å¢ƒ: {config.get('server', {}).get('environment', 'N/A')}")
    else:
        print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")


def main():
    parser = argparse.ArgumentParser(
        description="VMI ç»Ÿä¸€æµ‹è¯•å…¥å£",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    python3 run_tests.py --all           # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    python3 run_tests.py --quick         # å¿«é€ŸéªŒè¯
    python3 run_tests.py --validation    # æ¡†æ¶éªŒè¯æµ‹è¯•
    python3 run_tests.py --module        # æ¨¡å—æµ‹è¯•
    python3 run_tests.py --concurrent    # å¹¶å‘æµ‹è¯•
    python3 run_tests.py --scenario      # åœºæ™¯æµ‹è¯•
    python3 run_tests.py --aging 30      # 30åˆ†é’Ÿè€åŒ–æµ‹è¯•
    python3 run_tests.py --multi-tenant  # å¤šç§Ÿæˆ·æµ‹è¯•
    python3 run_tests.py --pytest --all  # ä½¿ç”¨ pytest è¿è¡Œæ‰€æœ‰æµ‹è¯•
        """,
    )

    parser.add_argument("--all", action="store_true", help="è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    parser.add_argument("--quick", action="store_true", help="è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆæ¡†æ¶éªŒè¯ï¼‰")
    parser.add_argument("--validation", action="store_true", help="è¿è¡Œæ¡†æ¶éªŒè¯æµ‹è¯•")
    parser.add_argument("--concurrent", action="store_true", help="è¿è¡Œå¹¶å‘æµ‹è¯•")
    parser.add_argument("--scenario", action="store_true", help="è¿è¡Œåœºæ™¯æµ‹è¯•")
    parser.add_argument("--aging", type=int, metavar="MINUTES", help="è¿è¡Œè€åŒ–æµ‹è¯•")
    parser.add_argument("--multi-tenant", action="store_true", help="è¿è¡Œå¤šç§Ÿæˆ·æµ‹è¯•")
    parser.add_argument("--module", action="store_true", help="è¿è¡Œæ¨¡å—æµ‹è¯•")
    parser.add_argument("--pytest", action="store_true", help="ä½¿ç”¨ pytest è¿è¡Œæµ‹è¯•")
    parser.add_argument("--check-config", action="store_true", help="æ£€æŸ¥é…ç½®çŠ¶æ€")

    args = parser.parse_args()

    if not any(vars(args).values()):
        parser.print_help()
        return

    print("ğŸš€ VMI æµ‹è¯•ç³»ç»Ÿ")
    print("=" * 60)
    print(f"è¿è¡Œæ¨¡å¼: {'pytest' if args.pytest else 'unittest'}")
    print(f"é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
    print("=" * 60)

    results = []

    if args.check_config:
        check_config_status()
        return

    if args.all:
        results = run_all_tests(args.pytest)
    elif args.quick:
        results = run_quick_tests(args.pytest)
    else:
        if args.validation:
            results.append(("æ¡†æ¶éªŒè¯æµ‹è¯•", *run_validation_tests(args.pytest)))
        if args.concurrent:
            results.append(("å¹¶å‘æµ‹è¯•", *run_concurrent_tests(args.pytest)))
        if args.scenario:
            results.append(("åœºæ™¯æµ‹è¯•", *run_scenario_tests(args.pytest)))
        if args.aging:
            results.append(
                (
                    f"è€åŒ–æµ‹è¯• ({args.aging}åˆ†é’Ÿ)",
                    *run_aging_tests(args.aging, args.pytest),
                )
            )
        if args.multi_tenant:
            results.append(("å¤šç§Ÿæˆ·æµ‹è¯•", *run_multi_tenant_tests(args.pytest)))
        if args.module:
            results.append(("æ¨¡å—æµ‹è¯•", *run_module_tests(args.pytest)))

    if results:
        generate_report(results)

        failed_tests = [name for name, success, _ in results if not success]
        if failed_tests:
            print(f"\nâŒ ä»¥ä¸‹æµ‹è¯•å¤±è´¥: {', '.join(failed_tests)}")
            sys.exit(1)
        else:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
            sys.exit(0)
    else:
        print("æ²¡æœ‰æ‰§è¡Œä»»ä½•æµ‹è¯•")


if __name__ == "__main__":
    main()
